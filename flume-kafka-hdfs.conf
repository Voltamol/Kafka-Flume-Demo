# Flume Agent Configuration for Kafka-to-HDFS
agent.sources = kafka-source
agent.channels = file-channel
agent.sinks = hdfs-sink

# ============================================================================
# SOURCE: Reads from the Kafka 'orders' Topic
# ============================================================================
agent.sources.kafka-source.type = org.apache.flume.source.kafka.KafkaSource
agent.sources.kafka-source.kafka.bootstrap.servers = localhost:9092
# Reads from the orders topic
agent.sources.kafka-source.kafka.topics = orders 
# *** CRUCIAL FIX ***: Ensures Flume reads messages sent before it started
agent.sources.kafka-source.kafka.auto.offset.reset = earliest
agent.sources.kafka-source.kafka.consumer.group.id = flume-archiver

# ============================================================================
# CHANNEL: File Channel (More robust than memory for production)
# ============================================================================
agent.channels.file-channel.type = file
agent.channels.file-channel.checkpointDir = /tmp/flume/checkpoint
agent.channels.file-channel.dataDirs = /tmp/flume/data

# ============================================================================
# SINK: Write Order Data to HDFS (for analysis/archival)
# ============================================================================
agent.sinks.hdfs-sink.type = hdfs
agent.sinks.hdfs-sink.channel = file-channel
agent.sinks.hdfs-sink.hdfs.path = hdfs://localhost:9000/archive/orders/%Y-%m-%d
agent.sinks.hdfs-sink.hdfs.filePrefix = orders-archive
agent.sinks.hdfs-sink.hdfs.fileSuffix = .json
# Roll file every 60 seconds
agent.sinks.hdfs-sink.hdfs.rollInterval = 60 
# Roll file every 10MB
agent.sinks.hdfs-sink.hdfs.rollSize = 10485760 
agent.sinks.hdfs-sink.hdfs.fileType = DataStream
agent.sinks.hdfs-sink.hdfs.writeFormat = Text

# Bind source and sink to the channel
agent.sources.kafka-source.channels = file-channel
agent.sinks.hdfs-sink.channel = file-channel